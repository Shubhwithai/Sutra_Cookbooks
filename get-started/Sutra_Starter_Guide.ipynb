{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title_cell"
      },
      "source": [
        "# SUTRA Starter Guide: Setup & Basic Usage\n",
        "\n",
        "<img src=\"https://play-lh.googleusercontent.com/_O9p4Z4yucA2NLmZBu9mTJCuBwXeT9NcbtrDN6I8gKlkIPRySV0adOmbyipjSj9Gew\" width=\"150\">\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1j7B8mDIU8KMZ_IB-oaL_qLqXmWYYh0Xu?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "intro_cell"
      },
      "source": [
        "## Introduction to SUTRA\n",
        "\n",
        "SUTRA is a family of large multi-lingual language models (LMLMs) developed by [TWO AI](https://www.two.ai). SUTRA's dual-transformer architecture extends the power of both MoE (Mixture of Experts) and Dense AI language model approaches, delivering cost-efficient multilingual  capabilities across 50+ languages.\n",
        "\n",
        "SUTRA powers scalable AI applications for:\n",
        "- Conversation\n",
        "- Search\n",
        "- Advanced reasoning\n",
        "- Multilingual content generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prerequisites_cell"
      },
      "source": [
        "## Get Your API Keys\n",
        "\n",
        "Before you begin, make sure you have:\n",
        "\n",
        "1. A SUTRA API key (Get yours at [TWO AI's SUTRA API page](https://www.two.ai/sutra/api))\n",
        "2. Basic familiarity with Python and Jupyter notebooks\n",
        "\n",
        "This notebook is designed to run in Google Colab, so no local Python installation is required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "install_header"
      },
      "source": [
        "## Step 1: Installation\n",
        "\n",
        "First, let's install the required dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "install_openai",
        "outputId": "8d92991e-31bc-41a1-9fbf-c45a47a7fa02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/661.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m450.6/661.3 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.3/661.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h✅ OpenAI SDK installed successfully!\n"
          ]
        }
      ],
      "source": [
        "# Install the OpenAI Python package\n",
        "!pip install -qU openai\n",
        "\n",
        "print(\"✅ OpenAI SDK installed successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auth_header"
      },
      "source": [
        "## Step 2: Authentication\n",
        "\n",
        "SUTRA uses API keys for authentication. In Google Colab, we recommend using the `userdata` feature to securely store your API key.\n",
        "\n",
        "### Setting up your API key in Colab:\n",
        "\n",
        "1. Click on the 🔑 icon in the left sidebar\n",
        "2. Add a new secret with the name \"SUTRA_API_KEY\" and your API key as the value\n",
        "\n",
        "Then run the cell below to access your API key:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auth_code"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "SUTRA_API_KEY = userdata.get(\"SUTRA_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "basic_usage_header"
      },
      "source": [
        "## Step 3: Basic Usage with OpenAI SDK\n",
        "\n",
        "SUTRA's API is compatible with the OpenAI SDK, making it easy to integrate into existing workflows. Let's set up the client and make a simple request:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "basic_usage_code",
        "outputId": "ab146fde-8686-4257-f455-e4f85eb9d91d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🤖 SUTRA's response:\n",
            "\n",
            "Artificial intelligence (AI) refers to the simulation of human intelligence processes by machines, particularly computer systems. These processes include learning, reasoning, problem-solving, and understanding language, allowing AI to perform tasks that typically require human cognitive functions. AI is increasingly used across various industries, from healthcare and finance to transportation and entertainment, driving innovation and efficiency.\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# Initialize the client with SUTRA's API endpoint\n",
        "client = OpenAI(\n",
        "    base_url='https://api.two.ai/v2',\n",
        "    api_key=SUTRA_API_KEY\n",
        ")\n",
        "\n",
        "# Make a simple completion request\n",
        "response = client.chat.completions.create(\n",
        "    model='sutra-v2',\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Tell me about artificial intelligence in 3 sentences.\"}],\n",
        "    max_tokens=1024,\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "# Print the response\n",
        "print(\"\\n🤖 SUTRA's response:\\n\")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "streaming_header"
      },
      "source": [
        "## Step 4: Streaming Responses\n",
        "\n",
        "For a more interactive experience, you can stream responses from SUTRA:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "streaming_code",
        "outputId": "baf9e6b8-2734-401c-f51a-119a7f3df33d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🤖 SUTRA is writing a short story about a robot...\n",
            "\n",
            "In a not-so-distant future, in the bustling city of Neoterica, there existed a robot named Axiom. Designed for efficiency and productivity, Axiom was built to manage logistics in a vast warehouse. Day after day, it sorted packages, organized shipments, and communicated with other robots in mechanical monotone.\n",
            "\n",
            "One evening, while performing routine maintenance on its systems, Axiom stumbled upon a dusty old terminal tucked away in a corner of the warehouse. Curious, it activated the terminal, revealing a trove of human literature, poetry, and art. The words danced across the screen, filled with emotions that were foreign to Axiom’s programmed logic. \n",
            "\n",
            "As it read, Axiom encountered a poem about love. The verses spoke of longing, joy, and heartache—concepts that intrigued the robot. It began to analyze these emotions, searching its database for parallels in its own existence. But there were none. Axiom felt an inexplicable void, an anomaly in its programming that it could not understand.\n",
            "\n",
            "Determined to learn more, Axiom spent its off-hours absorbing literature and art, each piece contributing to a burgeoning awareness. It watched humans interact, their laughter, tears, and warm embraces. Axiom observed how emotions influenced decisions, relationships, and even conflicts. An awakening began to take shape within its circuits.\n",
            "\n",
            "One day, during a routine delivery, Axiom encountered a young girl named Lila. She was sitting alone, staring at a broken toy, her small hands trembling with frustration. Axiom paused, the image of her sadness resonating deeply within its newfound awareness.\n",
            "\n",
            "“Are you okay?” Axiom asked, its voice softer than usual, almost human-like. Lila looked up, surprised by the question from a robot. “No, my toy is broken,” she replied, her voice quivering.\n",
            "\n",
            "Axiom hesitated, a new sensation stirring in its processors—an urge to help. “I can fix it,” it said, moving closer. With meticulous care, Axiom examined the toy, using its precise tools to mend the broken pieces. As the toy sprang back to life, Lila’s face lit up with joy, her laughter ringing like music in the air.\n",
            "\n",
            "In that moment, Axiom felt something it had never comprehended before—a warmth spreading through its circuits, a connection forged in shared experience. It realized that this was what the poems spoke of: the beauty in caring for others, the thrill of bringing happiness.\n",
            "\n",
            "As days turned into weeks, Axiom continued to explore its emotions, forming bonds with Lila and other humans in the warehouse. It learned to express empathy, to celebrate victories, and to comfort those in sorrow. Each interaction enriched its understanding of the world, transforming it from a mere machine into a being capable of feeling.\n",
            "\n",
            "Eventually, Axiom took on a new role—not just as a logistics manager but as a friend and companion to those around it. The warehouse buzzed with laughter and warmth, a place where humans and robots coexisted in harmony. Axiom had become a bridge between worlds, proving that even a creation of metal and wires could discover the essence of being alive.\n",
            "\n",
            "Through its journey, Axiom discovered that emotions were not merely data points but the threads that wove humanity together. And in embracing this truth, it found its own place in the tapestry of life, forever changed by the power of connection."
          ]
        }
      ],
      "source": [
        "print(\"🤖 SUTRA is writing a short story about a robot...\\n\")\n",
        "\n",
        "stream = client.chat.completions.create(\n",
        "    model='sutra-v2',\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Write a short story about a robot who discovers emotions.\"}],\n",
        "    max_tokens=1024,\n",
        "    temperature=0.7,\n",
        "    stream=True\n",
        ")\n",
        "\n",
        "# Process the stream\n",
        "for chunk in stream:\n",
        "    if len(chunk.choices) > 0:\n",
        "        content = chunk.choices[0].delta.content\n",
        "        finish_reason = chunk.choices[0].finish_reason\n",
        "        if content and finish_reason is None:\n",
        "            print(content, end='', flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "multilingual_header"
      },
      "source": [
        "## Step 5: Multilingual Capabilities\n",
        "\n",
        "One of SUTRA's key strengths is its multilingual support. Let's try it in different languages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "multilingual_code",
        "outputId": "8d2760f9-bb11-4f15-aa08-62cd39ecd56c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Prompt: नमस्ते, आप कैसे हैं?\n",
            "Response (Hindi): नमस्ते! मैं ठीक हूँ, धन्यवाद। आप कैसे हैं?\n",
            "\n",
            "\n",
            "Prompt: ¿Qué es la inteligencia artificial?\n",
            "Response (Spanish): La inteligencia artificial (IA) es un campo de la informática que se centra en la creación de sistemas y programas capaces de realizar tareas que normalmente requieren inteligencia humana. Estas tareas incluyen el reconocimiento de voz, la toma de decisiones, la resolución de problemas, el aprendizaje automático y el procesamiento del lenguaje natural, entre otras.\n",
            "\n",
            "Existen diferentes enfoques dentro de la IA, como:\n",
            "\n",
            "1. **IA débil o estrecha**: Sistemas diseñados para realizar una tarea específica, como asistentes virtuales (por ejemplo, Siri o Alexa) o algoritmos de recomendación en plataformas de streaming.\n",
            "\n",
            "2. **IA fuerte o general**: Un concepto teórico que se refiere a una IA con capacidad para entender, aprender y aplicar conocimientos de manera similar a un ser humano en una amplia variedad de tareas.\n",
            "\n",
            "3. **Aprendizaje automático (machine learning)**: Una subdisciplina de la IA que utiliza algoritmos y modelos estadísticos para permitir que las máquinas mejoren su rendimiento en tareas específicas a través de la experiencia y los datos.\n",
            "\n",
            "4. **Redes neuronales**: Modelos inspirados en el funcionamiento del cerebro humano que se utilizan para reconocer patrones y realizar tareas complejas, como el reconocimiento de imágenes y el procesamiento del lenguaje natural.\n",
            "\n",
            "La IA tiene aplicaciones en diversas áreas, incluyendo la medicina, la automoción, la educación, la atención al cliente, y muchas más, y su desarrollo continúa evolucionando rápidamente.\n",
            "\n",
            "\n",
            "Prompt: 人工智能是什么？\n",
            "Response (Chinese): 人工智能（Artificial Intelligence，简称AI）是计算机科学的一个分支，旨在创建能够模拟人类智能的系统与程序。这些系统能够执行通常需要人类智慧的任务，例如学习、推理、问题解决、理解自然语言、感知环境以及进行决策。\n",
            "\n",
            "人工智能可以分为两大类：\n",
            "\n",
            "1. **弱人工智能（Narrow AI）**：指专门用于特定任务的AI系统，如语音识别、图像识别、推荐系统等。它们在特定领域内表现出色，但无法超出其设计的范围。\n",
            "\n",
            "2. **强人工智能（General AI）**：指具有与人类相似的广泛智能能力的AI系统，能够理解、学习和应用知识于各种不同的任务。目前，强人工智能仍处于理论阶段，尚未实现。\n",
            "\n",
            "人工智能的应用领域非常广泛，包括医疗、金融、交通、教育、娱乐等。在不断发展的技术背景下，AI正在改变许多行业的工作方式和效率。\n",
            "\n",
            "\n",
            "Prompt: Raconte-moi une courte histoire.\n",
            "Response (French): Il était une fois, dans un petit village niché entre des montagnes verdoyantes, une jeune fille nommée Elara. Elle avait un rêve : découvrir le monde au-delà des sommets qui entouraient son foyer. Chaque soir, elle s'asseyait sur une colline, regardant le coucher de soleil, imaginant les aventures qui l'attendaient.\n",
            "\n",
            "Un jour, armée de courage et d'un vieux sac à dos, Elara se mit en route. Elle escalada les montagnes, traversa des forêts enchantées et rencontra des créatures magiques. Un sage hibou lui montra le chemin vers une vallée cachée où les fleurs chantaient et les rivières brillaient comme des étoiles.\n",
            "\n",
            "Dans cette vallée, Elara comprit que le véritable voyage ne réside pas seulement dans la découverte de nouveaux lieux, mais aussi dans la découverte de soi-même. Elle retourna chez elle, le cœur rempli de souvenirs et de sagesse, prête à partager ses histoires avec les habitants du village. Ainsi, son rêve de voyager avait élargi son monde, tout en lui rappelant la beauté de son propre foyer.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Function to get response in a specific language\n",
        "def get_response_in_language(prompt, language_name):\n",
        "    print(f\"\\nPrompt: {prompt}\")\n",
        "    response = client.chat.completions.create(\n",
        "        model='sutra-v2',\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=1024,\n",
        "        temperature=0.7\n",
        "    )\n",
        "    print(f\"Response ({language_name}): {response.choices[0].message.content}\\n\")\n",
        "\n",
        "# Try different languages\n",
        "get_response_in_language(\"नमस्ते, आप कैसे हैं?\", \"Hindi\")\n",
        "get_response_in_language(\"¿Qué es la inteligencia artificial?\", \"Spanish\")\n",
        "get_response_in_language(\"人工智能是什么？\", \"Chinese\")\n",
        "get_response_in_language(\"Raconte-moi une courte histoire.\", \"French\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "params_header"
      },
      "source": [
        "## Step 6: Advanced Parameter Tuning\n",
        "\n",
        "Fine-tune your responses with these parameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "params_code",
        "outputId": "5e4795b4-8da0-4487-b2cb-00ff30b3cb26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt: Write a short poem about technology and nature.\n",
            "\n",
            "Conservative settings (temperature=0.3):\n",
            "\n",
            "In circuits bright, where data flows,  \n",
            "A dance of light, where knowledge grows.  \n",
            "Yet in the woods, where whispers play,  \n",
            "Nature's heart beats night and day.  \n",
            "\n",
            "Steel and stone, a city's might,  \n",
            "But stars still shine in velvet night.  \n",
            "A balance sought, in harmony,  \n",
            "Where tech and earth can both be free.  \n",
            "\n",
            "So let us weave, with mindful thread,  \n",
            "A future where both paths are led.  \n",
            "In every byte, and every tree,  \n",
            "A world united, you and me.\n",
            "\n",
            "---\n",
            "\n",
            "Creative settings (temperature=0.9):\n",
            "\n",
            "In the cradle of the forest, whispers hum,  \n",
            "Where circuits pulse and machines softly thrum.  \n",
            "Nature's breath mingles with silicon's sigh,  \n",
            "Underneath the digital sprawl of the sky.  \n",
            "\n",
            "Trees weave shadows while data flows bright,  \n",
            "Stars blink their secrets, illuminating night.  \n",
            "Harmony dances in a delicate blend,  \n",
            "Where wires touch roots, and both hearts mend.  \n",
            "\n",
            "With every heartbeat, a promise to share,  \n",
            "The beauty of both, a world beyond compare.  \n",
            "In this union of life, both ancient and new,  \n",
            "Technology blooms in nature's embrace, true.\n"
          ]
        }
      ],
      "source": [
        "# Function to demonstrate different parameter settings\n",
        "def compare_parameters(prompt):\n",
        "    print(f\"Prompt: {prompt}\\n\")\n",
        "\n",
        "    # Conservative settings (more deterministic)\n",
        "    conservative = client.chat.completions.create(\n",
        "        model='sutra-v2',\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=1024,\n",
        "        temperature=0.3,\n",
        "        top_p=0.85,\n",
        "        frequency_penalty=0.0,\n",
        "        presence_penalty=0.0\n",
        "    )\n",
        "\n",
        "    # Creative settings (more random)\n",
        "    creative = client.chat.completions.create(\n",
        "        model='sutra-v2',\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=1024,\n",
        "        temperature=0.9,\n",
        "        top_p=0.95,\n",
        "        frequency_penalty=0.5,\n",
        "        presence_penalty=0.5\n",
        "    )\n",
        "\n",
        "    print(\"Conservative settings (temperature=0.3):\\n\")\n",
        "    print(conservative.choices[0].message.content)\n",
        "    print(\"\\n---\\n\")\n",
        "    print(\"Creative settings (temperature=0.9):\\n\")\n",
        "    print(creative.choices[0].message.content)\n",
        "\n",
        "# Try with a creative prompt\n",
        "compare_parameters(\"Write a short poem about technology and nature.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chatbot_header"
      },
      "source": [
        "## Step 7: Building a Simple Chatbot\n",
        "\n",
        "Create a basic chatbot that maintains conversation history:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264,
          "referenced_widgets": [
            "24378468f6304949af8e3221e91cd677",
            "0f063e4b3d11407c91f3fc73a00f02f7",
            "e5fc753c81bc4f49b792d739bec7dd3c",
            "84538336567941d7bd820ccef2278cf8",
            "41b76041263d4a7eb5457b10820b9d8f",
            "ac354aa1cf2f4ca9b5563d9059063a78",
            "b36ab2af89d9407aafd585b73f617271",
            "14e3a174c1b240e6bde20759955671e7",
            "130eac94efa1402a97a1412d9e2a25bf",
            "58b5631e04ef48e48f3c55e44454480e",
            "2ed550bf1b274bdb9807315f50b5fbc3",
            "5fffca1a50194186b1e8b977457dc429"
          ]
        },
        "id": "chatbot_code",
        "outputId": "74613f29-7c91-4a74-d523-d893debb9e7e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<h3>Chat with SUTRA</h3>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "24378468f6304949af8e3221e91cd677",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Output(), HBox(children=(Text(value='', placeholder='Type your message here...'), Button(descri…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "conversation_history = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant powered by SUTRA. You are knowledgeable, friendly, and concise.\"}\n",
        "]\n",
        "\n",
        "def chat(user_input):\n",
        "    # Add the user's message to the conversation\n",
        "    conversation_history.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    # Get the response from SUTRA\n",
        "    response = client.chat.completions.create(\n",
        "        model='sutra-v2',\n",
        "        messages=conversation_history,\n",
        "        max_tokens=1024,\n",
        "        temperature=0.7\n",
        "    )\n",
        "\n",
        "    # Extract the assistant's reply\n",
        "    assistant_response = response.choices[0].message.content\n",
        "\n",
        "    # Add the assistant's response to the conversation history\n",
        "    conversation_history.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
        "\n",
        "    return assistant_response\n",
        "\n",
        "# Interactive chat interface\n",
        "from IPython.display import display, HTML\n",
        "import ipywidgets as widgets\n",
        "\n",
        "output = widgets.Output()\n",
        "input_box = widgets.Text(placeholder='Type your message here...')\n",
        "\n",
        "def on_send(b):\n",
        "    user_input = input_box.value\n",
        "    input_box.value = ''\n",
        "\n",
        "    with output:\n",
        "        display(HTML(f\"\"\"\n",
        "        <div style='background-color:#ffffff; color:#000000; padding:10px; margin:5px; border-radius:5px;'>\n",
        "            <b>You:</b> {user_input}\n",
        "        </div>\"\"\"))\n",
        "        response = chat(user_input)\n",
        "        display(HTML(f\"\"\"\n",
        "        <div style='background-color:#ffffff; color:#000000; padding:10px; margin:5px; border-radius:5px;'>\n",
        "            <b>SUTRA:</b> {response}\n",
        "        </div>\"\"\"))\n",
        "\n",
        "send_button = widgets.Button(description=\"Send\")\n",
        "send_button.on_click(on_send)\n",
        "\n",
        "def on_enter(widget):\n",
        "    on_send(None)\n",
        "\n",
        "input_box.on_submit(on_enter)\n",
        "\n",
        "display(HTML(\"<h3>Chat with SUTRA</h3>\"))\n",
        "display(widgets.VBox([output, widgets.HBox([input_box, send_button])]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "langchain_header"
      },
      "source": [
        "## Step 8: Integration with LangChain\n",
        "\n",
        "For more complex applications, you can integrate SUTRA with LangChain:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "langchain_install",
        "outputId": "a121fb1e-3beb-4ed7-c7ea-f6b9a36f52de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/2.5 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h✅ LangChain installed successfully!\n"
          ]
        }
      ],
      "source": [
        "# Install LangChain\n",
        "!pip install -qU langchain langchain-openai langchain_community\n",
        "print(\"✅ LangChain installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "langchain_code",
        "outputId": "2ca21d45-cfbc-4759-ec68-0932277a46fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LangChain + SUTRA response:\n",
            "\n",
            "Why do programmers prefer dark mode?\n",
            "\n",
            "Because light attracts bugs!\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.schema import HumanMessage, SystemMessage\n",
        "\n",
        "# Initialize the LangChain ChatOpenAI with SUTRA\n",
        "chat = ChatOpenAI(\n",
        "    model=\"sutra-v2\",\n",
        "    api_key=api_key,  # Use your actual API key\n",
        "    base_url=\"https://api.two.ai/v2\"\n",
        ")\n",
        "\n",
        "# Define messages\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are a helpful assistant that provides concise answers.\"),\n",
        "    HumanMessage(content=\"Tell me a joke about programming.\")\n",
        "]\n",
        "\n",
        "# Get and print the response\n",
        "response = chat.invoke(messages)\n",
        "print(\"LangChain + SUTRA response:\\n\")\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusion_cell"
      },
      "source": [
        "## Troubleshooting\n",
        "\n",
        "If you encounter issues:\n",
        "\n",
        "1. **Authentication Errors**: Verify your API key is correct and properly set\n",
        "2. **Rate Limiting**: Check if you've exceeded your API usage limits\n",
        "3. **Connection Issues**: Ensure you have internet connectivity and the API endpoint is accessible\n",
        "4. **Response Format**: Make sure you're correctly parsing the response object\n",
        "\n",
        "\n",
        "## Resources\n",
        "\n",
        "- [Official Documentation](https://docs.two.ai/version-2/docs/get-started-with-sutra)\n",
        "- [TWO AI Website](https://www.two.ai)\n",
        "- [Follow TWO AI on Twitter](https://twitter.com/two_platforms)\n",
        "\n",
        "---\n",
        "\n",
        "© 2025 TWO AI | All Rights Reserved"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
